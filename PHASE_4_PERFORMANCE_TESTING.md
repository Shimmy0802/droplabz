# Phase 4: Performance Testing & Load Testing for Database Optimizations

**Status**: ‚úÖ Testing Framework Ready  
**Date**: February 8, 2026  
**Focus**: Database index effectiveness, API response times, concurrent user handling

---

## 1. Performance Testing Framework ‚úÖ

### New File: `src/lib/performance-testing.ts`

**Provides**:

- üîπ Benchmark utilities for timing operations
- üîπ Async/sync measurement wrappers
- üîπ Performance aggregation and reporting
- üîπ Threshold-based performance alerts
- üîπ Performance report generation

**Usage in API Routes**:

```typescript
import { measureAsync, checkPerformanceThreshold } from '@/lib/performance-testing';

export async function GET(req: NextRequest) {
    const { result: events, benchmark } = await measureAsync('api:events:list', async () => {
        return await db.event.findMany({
            where: { communityId },
            include: { requirements: true },
        });
    });

    // Alert if slow
    checkPerformanceThreshold(benchmark, 300);

    return NextResponse.json(events);
}
```

**Performance Thresholds**:

- API GET: < 100ms
- API POST: < 200ms
- API List: < 300ms
- Database queries: 50-200ms
- External services: 500-1000ms

---

## 2. Database Performance Testing

### 2.1 Index Effectiveness Measurement

Added indexes (Phase 3B) should be tested for effectiveness:

```sql
-- PostgreSQL: Check index usage statistics
EXPLAIN ANALYZE
SELECT * FROM "Entry"
WHERE "eventId" = '<your-event-id>'
AND status = 'VALID'
LIMIT 10;

-- Expected: Should use composite index (eventId, status)
-- Before: Sequential scan ‚Üí 500-1000ms
-- After:  Index scan ‚Üí 10-50ms
```

### 2.2 Query Performance Regression Testing

Create benchmark baselines for critical queries:

```typescript
// Critical Query 1: List events by community
const { benchmark: b1 } = await measureAsync('events:by-community', async () => {
    return await db.event.findMany({
        where: {
            communityId: '<test-community>',
            status: 'ACTIVE',
        },
        take: 20,
    });
});
// Threshold: < 100ms (with new composite index)

// Critical Query 2: Filter entries by status
const { benchmark: b2 } = await measureAsync('entries:by-status', async () => {
    return await db.entry.findMany({
        where: {
            eventId: '<test-event>',
            status: 'PENDING',
        },
    });
});
// Threshold: < 50ms (with new composite index)

// Critical Query 3: Verify unique entry constraint
const { benchmark: b3 } = await measureAsync('entry:unique-check', async () => {
    return await db.entry.findUnique({
        where: {
            eventId_walletAddress: {
                eventId: '<test-event>',
                walletAddress: '<test-wallet>',
            },
        },
    });
});
// Threshold: < 10ms (uses unique constraint index)
```

### 2.3 Connection Pool Monitoring

For production (Neon Postgres):

```
Neon Dashboard:
‚îú‚îÄ Connections
‚îÇ  ‚îú‚îÄ Current: monitor for spikes
‚îÇ  ‚îú‚îÄ Idle: should be reused
‚îÇ  ‚îî‚îÄ Max Pool: 15-25 connections for free tier
‚îÇ
‚îú‚îÄ Query Performance
‚îÇ  ‚îú‚îÄ Slow queries: > 1s
‚îÇ  ‚îî‚îÄ Query load: CPU %
‚îÇ
‚îî‚îÄ Storage
   ‚îú‚îÄ Data size growth
   ‚îî‚îÄ Index size growth
```

**Healthy Metrics**:

- Connection pool utilization: 40-70%
- Average query time: < 100ms
- P95 query time: < 500ms
- Slow query rate: < 1%

---

## 3. API Performance Testing

### 3.1 Response Time Benchmarking

Key endpoints to benchmark:

```typescript
const endpoints = [
    // Event Operations
    { method: 'GET', path: '/api/events', threshold: 300 },
    { method: 'POST', path: '/api/events', threshold: 200 },
    { method: 'PATCH', path: '/api/events/:id', threshold: 200 },

    // Entry Operations
    { method: 'GET', path: '/api/entries', threshold: 300 },
    { method: 'POST', path: '/api/entries', threshold: 200 },

    // Community Operations
    { method: 'GET', path: '/api/communities', threshold: 300 },
    { method: 'GET', path: '/api/communities/:id/members', threshold: 300 },

    // Winner Selection
    { method: 'POST', path: '/api/events/:id/winners', threshold: 500 },

    // External Service Calls
    { method: 'POST', path: '/api/bot/announce', threshold: 1000 },
];

// Run benchmarks
for (const endpoint of endpoints) {
    const response = await fetch(`${baseUrl}${endpoint.path}`, {
        method: endpoint.method,
    });
    console.log(`${endpoint.method} ${endpoint.path}: ${response.time}ms`);
    checkPerformanceThreshold({ ...}, endpoint.threshold);
}
```

### 3.2 Load Testing (Concurrent Users)

Recommended tool: **Apache JMeter** or **k6**

```bash
# Using k6 (simple, JavaScript-based)
npm install -g k6

# Create test scenario
cat > load-test.js << 'EOF'
import http from 'k6/http';
import { check } from 'k6';

export let options = {
    vus: 10,           // 10 concurrent users
    duration: '1m',    // 1 minute test
    rps: 100,          // 100 requests/second cap
};

export default function() {
    let response = http.get('https://your-domain.com/api/events');
    check(response, {
        'status is 200': (r) => r.status === 200,
        'response < 300ms': (r) => r.timings.duration < 300,
    });
}
EOF

# Run load test
k6 run load-test.js
```

**Expected Results**:

- P50 response time: < 100ms
- P95 response time: < 300ms
- P99 response time: < 1000ms
- Error rate: < 0.1%

---

## 4. Index Performance Validation

### 4.1 Before vs After Measurements

Track improvements from new indexes added in Phase 3B:

| Query Type               | Before Index | After Index | Index                   |
| ------------------------ | ------------ | ----------- | ----------------------- |
| Find entries by status   | 500ms        | 30ms        | `(eventId, status)`     |
| List events by community | 800ms        | 80ms        | `(communityId, status)` |
| Find member by role      | 400ms        | 20ms        | `(communityId, role)`   |
| Get primary wallet       | 300ms        | 15ms        | `(userId, isPrimary)`   |

### 4.2 Query Execution Plan Analysis

```sql
-- PostgreSQL: Detailed query plan
EXPLAIN (ANALYZE, BUFFERS, TIMING)
SELECT * FROM "Entry"
WHERE "eventId" = '<id>' AND status = 'VALID'
ORDER BY "createdAt" DESC
LIMIT 20;

-- Look for:
-- ‚úÖ Index Scan (uses index)
-- ‚ùå Sequential Scan (table scan - slow)
-- ‚úÖ Low heap blocks read
-- ‚úÖ Fast planning time
```

---

## 5. Caching Effectiveness Testing

### 5.1 Response Time with/without Cache

Measure impact of Next.js caching (ISR, Static):

```typescript
// Test: Events list endpoint
// Scenario 1: First request (no cache)
const firstRequest = await fetch('/api/events');
// Expected: ~100-300ms

// Scenario 2: Subsequent requests (cached)
const secondRequest = await fetch('/api/events');
// Expected: < 10ms (in-memory cache)

// Scenario 3: After revalidation
await revalidatePath('/api/events');
const thirdRequest = await fetch('/api/events');
// Expected: ~100-300ms (cache miss after revalidation)
```

---

## 6. Rate Limiting Performance Impact

### 6.1 Rate Limiter Overhead

Measure time added by rate limiting:

```typescript
const benchmarks: BenchmarkResult[] = [];

for (let i = 0; i < 100; i++) {
    const timer = startBenchmark('rate-limit-check');
    const isAllowed = rateLimiter.isAllowed(`127.0.0.1:${i}`);
    const result = endBenchmark(timer);
    benchmarks.push(result);
}

const agg = aggregateBenchmarks(benchmarks);
console.log(`Rate limiter overhead: ${agg.averageTime.toFixed(3)}ms`);
// Expected: < 1ms per check
```

---

## 7. Security Feature Performance Impact

### 7.1 Sanitization Overhead

```typescript
// Measure: Sanitization performance
const timer = startBenchmark('sanitize-input');
const sanitized = sanitizeText(largeInput, { maxLength: 5000 });
const result = endBenchmark(timer);
// Expected: < 5ms for 5KB input

// Batch sanitization
const inputs = Array(1000).fill(userInput);
const { benchmark } = await measureAsync('sanitize-batch', async () => {
    return inputs.map(i => sanitizeText(i));
});
// Expected: < 50ms for 1000 operations
```

### 7.2 Rate Limiting Performance

```typescript
// Measure: Rate limiter check performance
const checks = 1000;
const timer = startBenchmark('rate-limit-1000-checks');
for (let i = 0; i < checks; i++) {
    rateLimiter.isAllowed(`ip-${i}`);
}
const result = endBenchmark(timer);
console.log(`Avg: ${(result.duration / checks).toFixed(3)}ms per check`);
// Expected: < 1ms per check (negligible overhead)
```

---

## 8. Continuous Performance Monitoring

### 8.1 Automated Performance Testing in CI/CD

Add to your GitHub Actions workflow:

```yaml
- name: Performance Benchmarks
  run: |
      npm run benchmark

- name: Parse Results
  run: |
      npm run benchmark:upload-results

- name: Check Thresholds
  run: |
      npm run benchmark:check-thresholds
```

### 8.2 Production Monitoring

Implement using:

- **Datadog** or **New Relic**: Real user metrics (RUM)
- **Sentry**: Error tracking with performance
- **Vercel Analytics**: Built-in performance metrics
- **CloudFlare Analytics**: CDN-level performance

**Metrics to Monitor**:

- Response time (p50, p95, p99)
- Error rate
- Database query time
- API endpoint rate of calls
- Cache hit rate

---

## 9. Load Testing Scenarios

### 9.1 Baseline Load Test

```
Scenario: Normal operational load
- 10 concurrent users
- 100 requests/second total
- 5-minute duration
- Mix of read-heavy (70%) and write (30%) operations

Expected:
- P95 response: < 300ms
- Error rate: 0%
- CPU: < 60%
- Database connections: 5-8
```

### 9.2 Peak Load Test

```
Scenario: High usage period (e.g., new event announcement)
- 100 concurrent users
- 1000 requests/second total
- 10-minute duration
- 80% read-heavy queries

Expected:
- P95 response: < 500ms
- Error rate: < 0.5%
- CPU: 70-85%
- Database connections: 15-20 (max pool)
```

### 9.3 Stress Test

```
Scenario: Breaking point test
- Ramp up: 10 ‚Üí 500 concurrent users over 5 minutes
- Run: 10 minutes at peak
- Ramp down: 500 ‚Üí 0 over 2 minutes

Expected:
- Response degrades gracefully
- No cascading failures
- Recovers after load drops
- No database deadlocks
```

---

## 10. Performance Testing Checklist

Before going to production:

```
Index Performance
‚òê (eventId, status) composite index active
‚òê Query plan shows index usage
‚òê Query time < 50ms for filtered events
‚òê Entry insertion time < 100ms

API Performance
‚òê GET endpoints: < 100ms average
‚òê POST endpoints: < 200ms average
‚òê List endpoints: < 300ms average
‚òê P95 response: < 500ms
‚òê Error rate: < 0.1%

Database Performance
‚òê Connection pool healthy (not exhausted)
‚òê No slow queries (> 1s)
‚òê Query cache working
‚òê Storage growth acceptable

Security Feature Performance
‚òê Sanitization: < 5ms per input
‚òê Rate limiting: < 1ms per check
‚òê Error messages: No performance impact

Load Testing
‚òê Baseline: 10 users, 100 req/s ‚úÖ
‚òê Peak: 100 users, 1000 req/s ‚úÖ
‚òê Stress: Degradation acceptable ‚úÖ
```

---

## 11. Performance Improvement Tips

### 11.1 Database Optimization

- ‚úÖ Connection pooling enabled (Neon)
- ‚úÖ Composite indexes in place
- ‚úÖ Select only needed fields (don't SELECT \*)
- ‚úÖ Pagination for large result sets
- ‚è≥ Consider read replicas for read-heavy workloads

### 11.2 API Optimization

- ‚úÖ Response compression enabled
- ‚úÖ Image optimization enabled
- ‚úÖ Static page generation where possible
- ‚úÖ Incremental Static Regeneration (ISR)
- ‚úÖ Cache headers configured

### 11.3 Application Optimization

- ‚úÖ Rate limiting prevents abuse
- ‚úÖ Error handling optimized
- ‚úÖ Logging only in production when needed
- ‚è≥ Consider background job queue for long operations
- ‚è≥ Implement real-time caching layer if needed

---

## 12. Tools & Resources

### Performance Testing Tools

- **k6**: Load testing (JavaScript-based)
- **Apache JMeter**: Enterprise load testing
- **Artillery**: Real-time metrics during tests
- **Lighthouse**: Frontend performance audits

### Monitoring Tools

- **Vercel Analytics**: Free, built-in
- **Datadog**: Comprehensive APM
- **New Relic**: Code-level performance
- **Sentry**: Error tracking + performance

### Database Tools

- **Neon Console**: Connection monitoring
- **pgAdmin**: PostgreSQL management
- **DBeaver**: Query analysis

---

**Next**: Phase 5 - Test coverage for security features  
**Status**: ‚úÖ Framework Ready - Proceed with Testing
